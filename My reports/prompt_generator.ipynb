{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L58ql6GYklGG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    system_instruction=\"Humanize the below given 10 prompts by converting them into basic, simple, and concise one-liners. Keep the context and important keyword but use human-like language, including possible spelling mistakes and typos. The output should be less descriptive and shorter in length and should not contain technical terms except for basic keywords. Remember to just list the prompts only don't give any.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "advanced_df = pd.read_excel(\"500advanced.xlsx\", header=None)\n",
        "\n",
        "chunk_size = 10\n",
        "\n",
        "combined_rows = []\n",
        "\n",
        "for i in range(0, len(advanced_df), chunk_size):\n",
        "    chunk = advanced_df.iloc[i:i+chunk_size]\n",
        "    combined_row = \"\\n\".join([f\"{j+1}. {str(x)}\" for j, x in enumerate(chunk.values.tolist())])\n",
        "    combined_rows.append(combined_row)"
      ],
      "metadata": {
        "id": "QL0agG1il0RT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_prompts(advanced_prompt):\n",
        "    chat_session = model.start_chat(\n",
        "      history=[\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"parts\": [\n",
        "              \"1. ['Illustration, Eerie, an Environmental art of 1woman of 25yo, neon green hair, sulking, Ruined Kingdom of France']\\\\n2. ['sketch, woman wearing Pinafore dress and ruffled blouse, masterpiece, 8k, high resolution, shallow depth of field, sharp focus']\\\\n3. ['Neon Cyborg, abstract contemporary, feminism, installation, mixed-media, organic Metal particles and pieces in the air Envision an ancient robotic humanshaped Computer standing in a vast, sun-kissed prairie. The boundless expanse stretches to the horizon, and the robotic human graceful figure harmonizes with the natural beauty of the open wasteland. Pencil sketch, sketch']\\\\n4. ['(masterpiece, best quality:1.1), (sketch:1.1), paper, no humans, (a rose:1.1), flower, stem, thorn, leaf, plant']\\\\n5. ['dynamic shot of a beautiful red ruby and (diamonds:1.2) scaled dragon|cat hybrid, (beautiful eyes, up close:1.3), macro, mythological creature, dream world, pencil sketch, pencil drawing, monochrome, highly detailed']\\\\n6. ['((masterpiece,best quality, detailed)), 1boy, male focus, (sketch:1.1), paper, monochrome, cropped torso, emotionless, looking at viewer, white shirt']\\\\n7. ['a black fat man, a straw hat, (farmer, dirty clothes:1.1), a field with wheat in the background, a ranch, warm lighting, cozy atmosphere']\\\\n8. ['by Matias Hannecke, (electrifying but extremely beautiful:1.4), (intricate details, masterpiece, best quality:1.4), in the style of Nicola Samori, Futuristic style, sleek, modern, ultramodern, cartoon']\\\\n9. ['(18yo redhead girl:1.2), makeup, graphic eyeliner, rouge, (choker:0.9), realistic skin texture, oversize knit sweater, (red:0.8)']\\\\n10. ['head tilt, upper body, pink hair, dress, (best quality, masterpiece ,ultra-detailed:1.1), 1girl, solo, looking at viewer, smile, 3d illustration']\",\n",
        "          ],\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"model\",\n",
        "          \"parts\": [\n",
        "              \"Here are the prompts, humanized and shortened:\\n\\n1.  Eerie pic of a girl with green hair, sad, France is ruined.\\n2.  Sketch of a woman in a fancy dress, super detailed.\\n3.  Neon robot lady in a field, pencil sketch.\\n4.  Sketch of a rose, no people.\\n5.  Dragon-cat with a ruby, close up, pencil sketch.\\n6.  Sketch of a boy, white shirt, looking at you.\\n7.  Black man, straw hat, farmer, wheat field.\\n8.  Cartoon in Nicola Samori style, futuristic, super detailed.\\n9.  Girl with red hair, makeup, big sweater.\\n10.  Girl with pink hair, smiling, looking at you, 3D. \\n\",\n",
        "          ],\n",
        "        },\n",
        "      ]\n",
        "    )\n",
        "    response = chat_session.send_message(advanced_prompt)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "tKlvbJWtk_Ub"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_formatted_prompts(combined_row):\n",
        "    while True:\n",
        "        response = convert_prompts(combined_row)\n",
        "        lines = response.split(\"\\n\")\n",
        "        formatted_prompts = []\n",
        "        for line in lines[2:]:\n",
        "            if line.strip():\n",
        "                formatted_prompts.append(line.lstrip(\"0123456789. \").strip())\n",
        "        if len(formatted_prompts) >= 10:\n",
        "            return formatted_prompts\n"
      ],
      "metadata": {
        "id": "vuxd89dzrfN6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "results = []\n",
        "for combined_row in combined_rows:\n",
        "    results.append(get_formatted_prompts(combined_row))\n",
        "    time.sleep(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "5Hz0CvqUpoOa",
        "outputId": "961242ba-e351-4bee-9f8e-7d7b0dc25c38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BlockedPromptException",
          "evalue": "block_reason: OTHER\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBlockedPromptException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-222debe09b8a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcombined_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_rows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_formatted_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-332ea2fc7fae>\u001b[0m in \u001b[0;36mget_formatted_prompts\u001b[0;34m(combined_row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_formatted_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mformatted_prompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d6ff93ced230>\u001b[0m in \u001b[0;36mconvert_prompts\u001b[0;34m(advanced_prompt)\u001b[0m\n\u001b[1;32m     16\u001b[0m       ]\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvanced_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config)\u001b[0m\n\u001b[1;32m    503\u001b[0m         )\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_automatic_function_calling\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtools_lib\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36m_check_response\u001b[0;34m(self, response, stream)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_feedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_reason\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockedPromptException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBlockedPromptException\u001b[0m: block_reason: OTHER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_df = pd.DataFrame({\"human_prompts\": [item for sublist in results for item in sublist]})\n",
        "excel_df = pd.DataFrame({\"advanced_prompt\": advanced_df.iloc[:, 0]})\n",
        "result_df = pd.concat([prompts_df, excel_df], axis=1)"
      ],
      "metadata": {
        "id": "B4FvFLPGp3Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "SmIU_s-Z3uGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_excel(\"500prompts.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "uFy9mqmzxVQx"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}